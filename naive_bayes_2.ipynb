{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3a4b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "33553  I really liked this Summerslam due to the look...  positive\n",
      "9427   Not many television shows appeal to quite as m...  positive\n",
      "199    The film quickly gets to a major chase scene w...  negative\n",
      "12447  Jane Austen would definitely approve of this o...  positive\n",
      "39489  Expectations were somewhat high for me when I ...  negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\\\\\User\\\\\\Downloads\\\\IMDB Dataset.csv\")\n",
    "\n",
    "\n",
    "df= df.sample(n=500, random_state=42)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e182bc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 500 entries, 33553 to 27658\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     500 non-null    object\n",
      " 1   sentiment  500 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 11.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c882d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    253\n",
      "positive    247\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c388c864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorization Örnek Özellikler:\n",
      "   aaaand  aamir  aaron  abandoned  abandoning  abandonment  abandons  abc  \\\n",
      "0       0      0      0          0           0            0         0    0   \n",
      "1       0      0      0          0           0            0         0    0   \n",
      "2       0      0      0          0           0            0         0    0   \n",
      "3       0      0      0          0           0            0         0    0   \n",
      "4       0      0      0          0           0            0         0    0   \n",
      "\n",
      "   abducted  abe  ...  zinger  ziploc  zippers  zipping  zombie  zombies  \\\n",
      "0         0    0  ...       0       0        0        0       0        0   \n",
      "1         0    0  ...       0       0        0        0       0        0   \n",
      "2         0    0  ...       0       0        0        0       0        0   \n",
      "3         0    0  ...       0       0        0        0       0        0   \n",
      "4         0    0  ...       0       0        0        0       0        0   \n",
      "\n",
      "   zomedy  zone  zorro  zuckermanfill  \n",
      "0       0     0      0              0  \n",
      "1       0     0      0              0  \n",
      "2       0     0      0              0  \n",
      "3       0     0      0              0  \n",
      "4       0     0      0              0  \n",
      "\n",
      "[5 rows x 13589 columns]\n",
      "\n",
      "TF-IDF Vectorization Örnek Özellikler:\n",
      "   aaaand  aamir  aaron  abandoned  abandoning  abandonment  abandons  abc  \\\n",
      "0     0.0    0.0    0.0        0.0         0.0          0.0       0.0  0.0   \n",
      "1     0.0    0.0    0.0        0.0         0.0          0.0       0.0  0.0   \n",
      "2     0.0    0.0    0.0        0.0         0.0          0.0       0.0  0.0   \n",
      "3     0.0    0.0    0.0        0.0         0.0          0.0       0.0  0.0   \n",
      "4     0.0    0.0    0.0        0.0         0.0          0.0       0.0  0.0   \n",
      "\n",
      "   abducted  abe  ...  zinger  ziploc  zippers  zipping  zombie  zombies  \\\n",
      "0       0.0  0.0  ...     0.0     0.0      0.0      0.0     0.0      0.0   \n",
      "1       0.0  0.0  ...     0.0     0.0      0.0      0.0     0.0      0.0   \n",
      "2       0.0  0.0  ...     0.0     0.0      0.0      0.0     0.0      0.0   \n",
      "3       0.0  0.0  ...     0.0     0.0      0.0      0.0     0.0      0.0   \n",
      "4       0.0  0.0  ...     0.0     0.0      0.0      0.0     0.0      0.0   \n",
      "\n",
      "   zomedy  zone  zorro  zuckermanfill  \n",
      "0     0.0   0.0    0.0            0.0  \n",
      "1     0.0   0.0    0.0            0.0  \n",
      "2     0.0   0.0    0.0            0.0  \n",
      "3     0.0   0.0    0.0            0.0  \n",
      "4     0.0   0.0    0.0            0.0  \n",
      "\n",
      "[5 rows x 13589 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text\n",
    "\n",
    "df['cleaned_review'] = df['review'].apply(clean_text)\n",
    "\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_count = count_vectorizer.fit_transform(X)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "X_count_df = pd.DataFrame(X_count.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "X_tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Count Vectorization Örnek Özellikler:\")\n",
    "print(X_count_df.head())\n",
    "\n",
    "print(\"\\nTF-IDF Vectorization Örnek Özellikler:\")\n",
    "print(X_tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8544e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_count, df['sentiment'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d22ab33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Performansı:\n",
      "Doğruluk: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.63      0.67        60\n",
      "    positive       0.53      0.62      0.57        40\n",
      "\n",
      "    accuracy                           0.63       100\n",
      "   macro avg       0.62      0.63      0.62       100\n",
      "weighted avg       0.64      0.63      0.63       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import numpy as np\n",
    "\n",
    "X_train_dense = X_train.todense()\n",
    "X_test_dense = X_test.todense()\n",
    "\n",
    "X_train_array = np.asarray(X_train_dense)\n",
    "X_test_array = np.asarray(X_test_dense)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_array)\n",
    "X_test_scaled = scaler.transform(X_test_array)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled, y_train)\n",
    "y_pred_gnb = gnb.predict(X_test_scaled)\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "print(\"GaussianNB Performansı:\")\n",
    "print(f\"Doğruluk: {accuracy_gnb}\")\n",
    "print(classification_report(y_test, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55042063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Performansı (Count Vectorization):\n",
      "Doğruluk: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.65      0.67        60\n",
      "    positive       0.52      0.57      0.55        40\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.61      0.61      0.61       100\n",
      "weighted avg       0.63      0.62      0.62       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import numpy as np\n",
    "\n",
    "X_train_dense2 = X_train2.todense()\n",
    "X_test_dense2 = X_test2.todense()\n",
    "\n",
    "X_train_array2 = np.asarray(X_train_dense2)\n",
    "X_test_array2 = np.asarray(X_test_dense2)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled2 = scaler.fit_transform(X_train_array2)\n",
    "X_test_scaled2 = scaler.transform(X_test_array2)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_scaled2, y_train2)\n",
    "y_pred_gnb2 = gnb.predict(X_test_scaled2)\n",
    "accuracy_gnb2 = accuracy_score(y_test2, y_pred_gnb2)\n",
    "print(\"GaussianNB Performansı (Count Vectorization):\")\n",
    "print(f\"Doğruluk: {accuracy_gnb2}\")\n",
    "print(classification_report(y_test2, y_pred_gnb2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888a255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Performansı (TF-IDF):\n",
      "Doğruluk: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.77      0.84        60\n",
      "    positive       0.72      0.90      0.80        40\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.82      0.83      0.82       100\n",
      "weighted avg       0.84      0.82      0.82       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mnb = mnb.predict(X_test)\n",
    "accuracy_mnb_tfidf = accuracy_score(y_test, y_pred_mnb)\n",
    "\n",
    "print(\"MultinomialNB Performansı (TF-IDF):\")\n",
    "print(f\"Doğruluk: {accuracy_mnb_tfidf}\")\n",
    "print(classification_report(y_test, y_pred_mnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "545f6f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB Performansı (Count Vectorization):\n",
      "Doğruluk: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88        60\n",
      "    positive       0.84      0.78      0.81        40\n",
      "\n",
      "    accuracy                           0.85       100\n",
      "   macro avg       0.85      0.84      0.84       100\n",
      "weighted avg       0.85      0.85      0.85       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb2 = MultinomialNB()\n",
    "mnb2.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred_mnb2 = mnb2.predict(X_test2)\n",
    "accuracy_mnb_count = accuracy_score(y_test2, y_pred_mnb2)\n",
    "\n",
    "print(\"MultinomialNB Performansı (Count Vectorization):\")\n",
    "print(f\"Doğruluk: {accuracy_mnb_count}\")\n",
    "print(classification_report(y_test2, y_pred_mnb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b54193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Performansı (TF-IDF):\n",
      "Doğruluk: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.84        60\n",
      "    positive       0.75      0.82      0.79        40\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.81      0.82      0.82       100\n",
      "weighted avg       0.82      0.82      0.82       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "bnb_tfidf = BernoulliNB()\n",
    "bnb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_bnb_tfidf = bnb_tfidf.predict(X_test)\n",
    "accuracy_bnb_tfidf = accuracy_score(y_test, y_pred_bnb_tfidf)\n",
    "\n",
    "print(\"BernoulliNB Performansı (TF-IDF):\")\n",
    "print(f\"Doğruluk: {accuracy_bnb_tfidf}\")\n",
    "print(classification_report(y_test, y_pred_bnb_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23abcb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB Performansı (Count Vectorization):\n",
      "Doğruluk: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.84        60\n",
      "    positive       0.75      0.82      0.79        40\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.81      0.82      0.82       100\n",
      "weighted avg       0.82      0.82      0.82       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bnb_count = BernoulliNB()\n",
    "bnb_count.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "y_pred_bnb_count = bnb_count.predict(X_test2)\n",
    "accuracy_bnb_count = accuracy_score(y_test2, y_pred_bnb_count)\n",
    "\n",
    "print(\"BernoulliNB Performansı (Count Vectorization):\")\n",
    "print(f\"Doğruluk: {accuracy_bnb_count}\")\n",
    "print(classification_report(y_test2, y_pred_bnb_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6736380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:629: FutureWarning: The default value for `force_alpha` will change to `True` in 1.4. To suppress this warning, manually set the value of `force_alpha`.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:635: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10. Use `force_alpha=True` to keep alpha unchanged.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi alpha değeri: {'alpha': 5.272727272727273}\n",
      "Optimize edilmiş MultinomialNB modelinin doğruluğu: 0.8150000000000001\n",
      "Optimize edilmiş MultinomialNB Performansı (Count Vectorization):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86        60\n",
      "    positive       0.77      0.85      0.81        40\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.83      0.84      0.84       100\n",
      "weighted avg       0.84      0.84      0.84       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "alpha_range1 = np.linspace(0, 2, 100)\n",
    "alpha_range2 = np.linspace(2, 4, 100)\n",
    "alpha_range3 = np.linspace(4, 6, 100)\n",
    "alpha_range4 = np.linspace(6, 8, 100)\n",
    "\n",
    "alpha_values = np.concatenate((alpha_range1, alpha_range2, alpha_range3, alpha_range4))\n",
    "\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train2, y_train2)\n",
    "\n",
    "print(\"En iyi alpha değeri:\", grid_search.best_params_)\n",
    "print(\"Optimize edilmiş MultinomialNB modelinin doğruluğu:\", grid_search.best_score_)\n",
    "\n",
    "y_pred_optimized = grid_search.predict(X_test2)\n",
    "print(\"Optimize edilmiş MultinomialNB Performansı (Count Vectorization):\")\n",
    "print(classification_report(y_test2, y_pred_optimized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a516f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lojistik Regresyon Modeli Performansı:\n",
      "Doğruluk: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.73      0.82        60\n",
      "    positive       0.70      0.93      0.80        40\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.82      0.83      0.81       100\n",
      "weighted avg       0.84      0.81      0.81       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Lojistik Regresyon Modeli Performansı:\")\n",
    "print(f\"Doğruluk: {accuracy_lr}\")\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bd8d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lojistik Regresyon Modeli Performansı:\n",
      "Doğruluk: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84        60\n",
      "    positive       0.74      0.85      0.79        40\n",
      "\n",
      "    accuracy                           0.82       100\n",
      "   macro avg       0.81      0.82      0.82       100\n",
      "weighted avg       0.83      0.82      0.82       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train2, y_train2)\n",
    "\n",
    "y_pred_lr2 = log_reg.predict(X_test2)\n",
    "\n",
    "accuracy_lr2 = accuracy_score(y_test2, y_pred_lr2)\n",
    "print(\"Lojistik Regresyon Modeli Performansı:\")\n",
    "print(f\"Doğruluk: {accuracy_lr2}\")\n",
    "print(classification_report(y_test2, y_pred_lr2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f43b2b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-En Yakın Komşu Modeli Performansı:\n",
      "Doğruluk: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.77      0.78        60\n",
      "    positive       0.67      0.70      0.68        40\n",
      "\n",
      "    accuracy                           0.74       100\n",
      "   macro avg       0.73      0.73      0.73       100\n",
      "weighted avg       0.74      0.74      0.74       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"K-En Yakın Komşu Modeli Performansı:\")\n",
    "print(f\"Doğruluk: {accuracy_knn}\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "995b2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-En Yakın Komşu Modeli Performansı:\n",
      "Doğruluk: 0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.22      0.34        60\n",
      "    positive       0.43      0.90      0.59        40\n",
      "\n",
      "    accuracy                           0.49       100\n",
      "   macro avg       0.60      0.56      0.46       100\n",
      "weighted avg       0.63      0.49      0.44       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "y_pred_knn2 = knn.predict(X_test2)\n",
    "\n",
    "accuracy_knn2 = accuracy_score(y_test2, y_pred_knn2)\n",
    "print(\"K-En Yakın Komşu Modeli Performansı:\")\n",
    "print(f\"Doğruluk: {accuracy_knn2}\")\n",
    "print(classification_report(y_test2, y_pred_knn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f866cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
